
Low-Power, ultra-Fast Deep Learning Neuromorphic Chip for Unmanned Aircraft Systems
===================================================================================

# Abstract


Artificial Intelligence realized through Machine Learning algorithms seems to be the only viable solution to implement perception, enable pilot assistants and eventually full autonomy to UAS. Currently, many UAS have some kind of conventional Computer Vision (CV) helping them in obstacle avoidance or target acquisition. Interestingly though, since 2012 Deep Neural Networks (DNN) have dramatically outperformed conventional CV algorithms in those tasks and pushed Artificial Intelligence (AI) limits in a variety of other applications including, but not limited, to object recognition, video analytics, decision making and control, speech recognition, etc. Unfortunately, the computational power required for real-time DNN operation can still only be delivered by bulky, expensive, slow, heavy and energy-hungry digital systems like GPUs.This is why Mentium  is devoted to delivering disruptive technology in the field of Machine Learning hardware accelerators, and in particular for this project, into the Deep Learning Hardware Accelerators field. Experimental data and Phase I results confirm that our hardware can deliver 100x to 1000x gain in speed and in power efficiency compared to other state-of-the-art accelerators. Our final product will be able to analyze, in real-time, big data streams coming from cameras, sensors and/or avionics and to categorize (classify) them for the purpose of decision making or object localization to achieve better navigation and collision avoidance in UAS. The same hardware processor will be deployable in the Air Traffic Systems, for real-time data analysis and decision-making. All with more than 10x reduction in cost and power consumption. This distruptive technology is based on an analog-computational core, exploiting the memory devices to carry out the computation at a physical level. Analog computation is inherently faster and more efficient than the digital one, while the in-memory computation removes the data transfer bottleneck.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
||2018|$754,497||
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards/JT/#361)