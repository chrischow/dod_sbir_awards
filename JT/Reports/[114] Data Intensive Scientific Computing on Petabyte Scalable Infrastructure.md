
Data Intensive Scientific Computing on Petabyte Scalable Infrastructure
=======================================================================

# Abstract


The infrastructure and programming paradigm for petabyte-level data processing performed at companies like Google and Yahoo shed some promising lights on the data-intensive scientific computing. Open source software and inexpensive commodity hardware make proprietary technologies within the grasp of academic communities. By leveraging these commercially proven and publicly available technologies, we are going to develop a suite of novel data management and analysis libraries, as an extension to existing primitive algorithms originally designed for web search. These libraries take advantage of the underlying petabyte-scalable data infrastructure, parallelize computation transparently and allow scientists and future commercial users to perform rather complex tasks (data mining, data visualization and machine learning) in a data intensive environment.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
||2009|$99,964|computer system architectures; database development and interfacing; software development environments; software tools for distributed analysis and simulation|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards/JT/#114)