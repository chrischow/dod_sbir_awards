
ArrayFire-ML: An Accelerated Open Source Machine Learning Primitives Library
============================================================================

# Abstract


Numerous machine learning frameworks exist, each with highly variable support for accelerated computing (e.g. Graphics Processing Units (GPUs), Field-Programmable Gate Arrays (FPGAs), etc). A library of machine learning primitives could support the many disparate frameworks and boost the advancement of machine learning research and programs, such as those underway in the DARPA Data-Driven Discovery of Models (D3M) program. This proposal seeks to build accelerated machine learning primitives into the ArrayFire Machine Learning Library (ArrayFire-ML). Features of ArrayFire-ML include: 1) transparent hardware acceleration due to ArrayFire’s ability to run on CUDA parallel computing platforms, within the Open Computing Language (OpenCL) framework, or on multi-core Central Processing Unit (CPU) devices, 2) support for many programming languages, including Python and Julia, via community language wrappers, 3) the robust and already deployed ArrayFire testing and documentation framework, 4) the active and broad existing ArrayFire open source community seeking additional machine learning functionality, and 5) with the proposed D3M primitives in ArrayFire-ML, all of ArrayFire’s existing math functions would become available for further research efforts on those primitives. In this proposal, we seek to provide a significant leap forward to the machine learning field by building a robust, open source library of accelerated machine learning primitives available to frameworks, the D3M program, and the broader research community.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
|Defense Advanced Research Projects Agency|2018|$1,499,383|machine learning, deep learning, artificial intelligence, tensorflow, gpu, scikit-learn, mallet, cuda|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards/CC/#1216)