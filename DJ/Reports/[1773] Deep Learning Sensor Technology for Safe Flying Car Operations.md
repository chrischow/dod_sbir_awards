
Deep Learning Sensor Technology for Safe Flying Car Operations
==============================================================

# Abstract


Sensor technology that enables safe takeoff, landing, navigation, and Sense & Avoid (SAA) flight is paramount for Urban Air Mobility (UAM). The approach must be all-weather, day-night, low C-SWaP, and identify obstacles during flight (aircraft, UAS, birds) as well as during takeoff/landing (cables, buildings). The FAA advises that an air vehicle be able to Detect, Sense, and Avoid (DSA) other aircraft with detection ranges of 3 nmi or more. We are proposing an Artificial Intelligence Radar (AIR) solution that is all-weather, extremely lightweight and cost effective.  It leverages a novel sensor technology, ISL’s state-of-the-art M&S tool RFView®, and the Simlat flight environment. RFView® was recently highlighted as an AFRL SBIR Success Story for its ability to dramatically reduce the need for expensive flight testing (www.sbir.gov/node/1526807). The ISL / Sinclair team has the qualifications, personnel, and tools to successfully develop and transition the proposed novel SAA solution. ISL has a track record of successful SBIR program transition to Phase IIIs and programs of record. Sinclair is an active research member of the FAA ASSURE UAS Center of Excellence and NSF Center for UAS Industry Advisory Board. Sinclair has demonstrated successful commercialization of UAS technology through a Binational Industrial Research and Development Foundation grant.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
|Air Force|2021|$149,935|detect sense and avoid, collision avoidance, urban air mobility, sense and avoid, artificial intelligence, deep learning, radar|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards/DJ/#1773)