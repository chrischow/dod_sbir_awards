
A PEA IN A POD
==============

# Abstract


ABSTRACT: While the ability to collect larger volumes of full-motion video (FMV) data grows, analysts within the ISR community struggle to keep pace with the volume, speed, and variety of collection. During Phase 1 Processing, Exploitation, and Dissemination (PED), analysts are required to collaborate with a distributed team of sensor operators, collection and mission managers, and other analysts while navigating and interpreting mounds of data across many disparate sources to produce actionable decisions. Given the pace of these data-intensive workflows, analysts frequently encounter a problem of information management, ranging from the coordination challenges associated with maintaining situational awareness and contextual knowledge while exploiting data across sensor types to identify potential targets, to retrieving, processing, and utilizing sensor data in a timely manner once collected. To address this need, Aptima proposes to develop the Adaptive Personalized Environment for Artificial Intelligence and Naturalistic Applications for PED Operational Domain (A PEA IN A POD). When fully implemented, A PEA IN A PODs advanced multimodal human-machine interfaces and interactions for Phase 1 PED of FMV data will improve information management and interaction between FMV analysts and the technologies they use, therefore creating efficiencies while reducing manpower requirements to support a wide range of ISR missions.; BENEFIT: A PEA IN A POD utilizes emerging technologies, such as immersive visualization, multimodal user interfaces, gesture tracking, speech recognition, and multi-touch, to help FMV analysts accomplish data-intensive PED tasks more quickly and effectively. Benefits include:Combining human analytical reasoning and the human visual system with the latest computational tools for analyzing, displaying, and interaction with information;The ability for users to contextualize and interpret sensor and information feeds in real-time via a more naturalistic, embodied experience;Increased analytic capacity and decreased cognitive load by using strategies for managing multimodal interactions in support of the analysts specific tasking;Increased situation awareness and reduced overall workload via context-driven user interfaces and interactions designed for ISR analysis tasks;Commercialization potential within the defense, homeland security, intelligence community, and healthcare markets.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
|Air Force|2016|$149,999|immersive multimodal workspace, human-machine interaction, context-driven user interface, ped, isr, fmv|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards#63)