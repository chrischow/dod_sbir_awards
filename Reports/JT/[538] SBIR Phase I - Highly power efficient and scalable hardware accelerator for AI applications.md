
SBIR Phase I: Highly power efficient and scalable hardware accelerator for AI applications
==========================================================================================

# Abstract


The broader impact of this Small Business Innovation Research (SBIR) Phase I project is providing faster, cheaper and lower power alternatives to central processing units (CPUs) and graphic processing units (GPUs), making machine learning more accessible to students, engineers and scientists. In general, this will lead to faster product development and shorter time-to-market in the artificial intelligence market. Highly power-efficient machine learning accelerators make training and complex inferences possible on so-called "Edge" devices and can revolutionize the way machine learning tasks are performed for end users. By enabling fast and power-efficient Edge computing, this innovation benefits society by reducing data traffic while preserving privacy and data security since data never leave the device. The Total Addressable Market for hardware accelerators for machine learning applications was estimated to be around $1B in 2017 but will likely grow at a 50% Compound Annual Growth Rate (CAGR) until 2025 to $66 B. High power-efficiency and scalability of this innovation gives it an immense competitive advantage to penetrate different segments within this market. The proposed project aims to develop a fast, scalable and area- and power-efficient matrix multiplier for machine learning applications. Matrix multiplication is at the heart of all machine learning algorithms and is the most computationally expensive task in these applications. Most hardware accelerator solutions store inputs, weights and partial sums in memory and retrieve them sequentially in order to perform matrix multiplication. The data movements between memory and computational units dominate the overall power consumption and latency of the system. By performing computations in memory, a significant power and area savings can be achieved. This SBIR project seeks to develop a technology to perform mixed-signal matrix multiplication in memory to significantly improve the speed and power- and area-efficiency of machine learning accelerators. Phase I will involve the design and verification of a matrix multiplier that can perform machine learning tasks more efficiently. This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
||2019|$224,996||
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards#538)