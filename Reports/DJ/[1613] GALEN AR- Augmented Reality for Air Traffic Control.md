
GALEN AR- Augmented Reality for Air Traffic Control
===================================================

# Abstract


AvaWatz GALEN AR uses Augmented Reality (AR) technology to solve a persistent problem for air traffic controllers: it enables the controller to look at the sky, runways, and taxiways, and see the location and identification of aircraft under his/her control, even when the actual aircraft is obscured by darkness, clouds, or obstruction. Constant visibility improves the controllerâ€™s situational awareness, leading to more efficient Air Traffic Control (ATC) operations and greater safety. It uses Head-Mounted Display (HMD) hardware built for AR to insert visual aircraft markers and labels into the controllerâ€™s natural field of vision. It takes in sensor data from aircraft transponders, approach radar and the HMDâ€™s camera it then employs Artificial Intelligence Machine Learning (AI/ML) to fuse the data and perform special Computer Vision tasks. The resulting augmented data and map of the visible world is inserted as visual marker and identifying text at the correct location of the aircraft in the HMD based on the view field of the controllerâ€™s position and orientation. Its architecture includes a novel Edge AR Cloud that reduces the systemâ€™s dependence on high-bandwidth network access and distinctive sensor data AR rendering.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
|Air Force|2019|$749,858|augmented reality, air traffic control, situational awareness, machine learning, simultaneous location and mapping, computer vision, edge ar cloud, sensor data fusion|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards/Reports/DJ/#1613)