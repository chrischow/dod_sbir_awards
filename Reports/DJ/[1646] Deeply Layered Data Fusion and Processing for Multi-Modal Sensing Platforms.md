
Deeply Layered Data Fusion and Processing for Multi-Modal Sensing Platforms
===========================================================================

# Abstract


As rapid and accurate analysis of ISR imagery and data continually grows to become a critical part of todayâ€™s Air Force and broader military missions, it is not sufficient to simply gather information from a single sensor, be it an optical camera, hyper / multispectral payload, thermal imager or LiDAR detector. Instead, layering-in multi-modal imagery and combining it with non-image based sources and sentiment analysis is critical for increasing the quality and fidelity of the intelligence ultimately being delivered for comprehensive CoA recommendations. NOVI proposes to address this need by applying its expertise in state-of-the-art neural net algorithms to combine edge-based multi-modal sensors with machine learning based data fusion and processing for unparalleled responsiveness and actionable intelligence. As part of the effort proposed herein, NOVI will work to identify problem sponsors suited for supporting a Phase II pilot trial, including identification of the necessary changes and enhancements needed to adapt its existing commercial algorithms to Air Force needs, and definition of a detailed program plan for implementation of such a pilot demonstration in a follow-on Phase II effort.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
|Air Force|2020|$48,535|fa04, artificial intelligence, machine learning, deeply-layered, multi-modal, image processing, sensors, data fusion|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards/Reports/DJ/#1646)