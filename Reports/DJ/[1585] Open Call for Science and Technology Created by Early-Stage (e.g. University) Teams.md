
Open Call for Science and Technology Created by Early-Stage (e.g. University) Teams
===================================================================================

# Abstract


Assess the feasibility of a novel technology which automatically generates human-understandable explanations of an artificial intelligence (AI) algorithmâ€™s decisions â€“ for example, a deep neural networkâ€™s (DNNâ€™s) classification decisions. Our technology, called EMERALD (Explainable Machine Reasoning through the Application of Linked Data), is designed to improve trust and transparency within human-in-the-loop AI systems by providing the human operator with an informed basis for accepting/rejecting/modifying the decisions of the AI. EMERALD works by leveraging background information contained within knowledge graphs to infer an AIâ€™s internal model of the world based on its external behaviors. EMERALD is designed to take advantage of ever-increasing volumes of structured semantic information (linked data) available on the Web. The recent proliferation of explicitly structured Semantic Web data (two prominent examples being Wikidata and the Google Knowledge Graph) has occurred at the same time as powerful â€œblack boxâ€� machine learning algorithms such as DNNs have become ubiquitous. Because these algorithms often encode information implicitly, their â€˜thought processesâ€™ defy easy interpretation. With EMERALD, we will capitalize on one AI trend (knowledge graphs) to improve the transparency and trustworthiness of another (machine learning). As such, our approach resides at the vanguard of so-called â€œthird-waveâ€� contextual AI Research.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
|Air Force|2019|$24,906|fa-002, explainable artificial intelligence, machine learning algorithms, machine reasoning, human-machine teaming, intelligence surveillance & reconnaissance, third-wave ai|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards/Reports/DJ/#1585)