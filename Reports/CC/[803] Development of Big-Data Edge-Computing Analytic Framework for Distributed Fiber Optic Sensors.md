
Development of Big-Data Edge-Computing Analytic Framework for Distributed Fiber Optic Sensors
=============================================================================================

# Abstract


In Carbon Capture and Storage CCS) projects, Distributed Fiber Optic Sensors DFOS) are being increasingly used to monitor and track the migration and location of carbon dioxide plumes and to identify potential anomalies due to leakage or microseismic events. Data from these sensing and monitoring sources needs to be transmitted to the surface, integrated, and analyzed in real- or near real- time so that storage security can be confirmed, and decisions can be made relative to operations. Due to the limitation of the network bandwidth, especially in remote areas, the communication of sensor data over the network would be time-consuming when the volume of communication is extremely large. For example, the distributed acoustic sensing DAS) is an emerging DFOS technology that transforms telecommunication fiber-optic cables into sensor arrays, enabling meter-scale recording over tens of kilometers of fiber length. DAS arrays can generate terabytes Tb) of new data per day, thus representing a type of Big Data, characterized by its high volume and speed. Currently, the data uploading speed over 4G wireless broadband is typically 2â€“5 Mbps Mb per second), making it impractical to transmit the actual DAS measurements in real time to the central server for decision making. Paulsson, Inc. PI), University of Texas at Austin UTA) and Battelle Memorial Institute will collaborate to develop an edge-computing data analytics system to more efficiently process and filter CCS DAS monitoring data on site. DAS measurements are both spatially and temporally high resolution, but also have strong redundancy. The characteristics of DAS data stream dictate that archiving all data is not practical and random access of the data is not feasible. The key to DAS data reduction is to exploit spatial redundancy in the DAS channels each channel is a sensor) and the temporal pattern in DAS stream for event extraction. This research proposes to apply a state-of-the-art deep learning based and edge-centric data analytics system to significantly reduce the size of DAS datasets while enabling extraction of meaningful events for uploading to the central servers for decision making. Edge computing refers to performing data processing on computing infrastructure that exists close to the sources of data. Real-time complex event processing is a process in which data-stream is quickly processed in order to extract real-time insights from it. Specifically, a deep-learning based event detection algorithm will be designed and implemented to recognize anomalous events from DAS measurements. The DAS event detection system will be trained and validated using archived DAS data, and then demonstrated at a real CCS site for performance benchmarking. Paulsson has extensive experience packaging and deploying optical seismic instruments in wells and processing the resulting data and will be the commercialization path for the developed large data volume processing technology. An improved understanding of the subsurface will allow for a more efficient Carbon Capture Utilization and Storage process.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
||2020|$200,000||
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards/Reports/CC/#803)