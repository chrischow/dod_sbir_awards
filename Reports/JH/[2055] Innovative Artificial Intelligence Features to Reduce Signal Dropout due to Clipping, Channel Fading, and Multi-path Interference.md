
Innovative Artificial Intelligence Features to Reduce Signal Dropout due to Clipping, Channel Fading, and Multi-path Interference
=================================================================================================================================

# Abstract


Orthogonal frequency-division multiplexing (OFDM) is the modulation protocol underlying modern communications networks, such as 5G mobile networks. It works by transmitting a serial symbol sequence in parallel over many orthogonal subcarriers, which enables longer symbol duration and simpler channel equalization. However, OFDM suffers from a high peak to average power ratio, which typically leads to clipping and an elevated bit error ratio (BER) when processed with linear detectors, as well as multi-path fading due to scatterers and the motion of the transmitter and receiver. When the BER becomes too high for forward error correction to compensate, the signal connection must be reestablished and previously transmitted data is lost, greatly curtailing the overall data throughput. It is therefore desirable to develop a nonlinear algorithm to correct for the effects of clipping and fading so the BER remains acceptable and renegotiation of the link is not required, thus improving overall data throughput. The RACER concept is a proposed machine learning framework to perform nonlinear processing of the received signal to maintain acceptable BERs that can be compensated for with forward error correction.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
|Navy|2020|$146,456|machine learning, orthogonal frequency division multiplexing, reservoir computing|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards#2055)