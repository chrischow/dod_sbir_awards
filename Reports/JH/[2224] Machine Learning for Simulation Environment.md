
Machine Learning for Simulation Environment
===========================================

# Abstract


Areté and the Machine Learning for Artificial Intelligence (MLAI) Lab at the University of Arizona (UofA) will develop an interactive scenario building tool capable of generating realistic synthetic 360° videos in real-time for use in training simulators for periscope operators .  We refer to this solution as RealSynth360.  This novel capability will be created by combining the latest advances in generative adversarial networks (GANs), the simulation capabilities of the Unreal Engine, and Areté’s experience in building periscope technologies.  Areté’s tiered-GAN approach is structured such that panoramic videos of dynamically created mission simulations can by reified in real-time across two processes.  The first tier is responsible for translating the simulated synthetic environmental backgrounds into realistic environmental backgrounds.  The second tier is responsible for blending synthetic examples of primitive object(s) (i.e. ships, buoys, land masses, etc.) with matching real world object(s) to complete the generation realistic synthetic imagery.  Areté’s overarching goal is to increase the fidelity of the simulated sensor imagery used within the Submarine Multi-Mission Team Trainer (SMMTT).  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
|Navy|2020|$140,000|gp-gan, cyclegan, dynamic scene synthesis, unreal engine, generative adversarial models, dynamic simulation, training simulators, machine learning|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards#2224)