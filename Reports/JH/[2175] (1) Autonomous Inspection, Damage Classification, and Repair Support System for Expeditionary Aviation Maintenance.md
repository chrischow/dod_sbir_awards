
(1) Autonomous Inspection, Damage Classification, and Repair Support System for Expeditionary Aviation Maintenance
==================================================================================================================

# Abstract


Emerging Technology Ventures Inc. (ETV) is proposing to develop and demonstrate an end-to-end system to inspect aviation assets using an unmanned aerial system (UAS) deployed with a multi-modal sensor, artificial intelligence (AI) driven analytics to detect and classify damage to the operator, and AI driven work order system to facilitate repairs in expeditionary operations. The proposal is in response to Focus Area 1, Expeditionary Depot Capability, and Focus Area 2, AI Generated Work Instructions. The effort leverages completed and ongoing work at ETV. This project, UAS inspection and predictive analytics for condition-based maintenance of wind turbines, encompasses the key elements of the proposed technical effort which will adapt the technology to expeditionary aviation maintenance in austere and contested environments. The end state minimum viable prototype (MVP) will be demonstrated in an aviation maintenance environment with the constraints expected to be encountered in an expeditionary environment including limited maintenance personnel, tactical operations driven operational tempo, and constrained or denied communications and network capability. Key components of the TRL 6 systems demonstration include: Sense: A UAS with a multi-modal sensor suite will be demonstrated to acquire inspection data from an aviation asset. The unit will acquire visual, LiDAR, and representative structural data from an embedded sensor. An IR sensor will also be integrated for future subsurface anomaly detection capability. The ability to utilize aircraft drawings for anomaly position location will also be demonstrated. Inspection time will be captured along with maintainer feedback for comparison to current manual methods to measure OPTEMPO improvements in a tactical environment. Understand and Decide:Â  The computing environment to support the analysis will include edge computing with the NVDIA Jetson Nano and cloud services which are currently being provisioned through Amazon Web Services and Microsoft Azure. Realizing that the tactical environment may have limited bandwidth, maximum edge computing capacity will be demonstrated. A representative tactical network will be deployed to baseline the ability to send critical data (spare requests, asset availability, and SME communication). The Neural Network Engine (NNE) will utilize datasets for strikes (lightning, birds, debris, enemy weapons), structural cracks, and leading-edge erosion for the MVP. The ability of the NNE to detect and classify faults will be measured. Act: The AI driven workflow will present the inspection findings to a graphical user interface (GUI) that will be tablet or ruggedized laptop. The GUI will demonstrate the ability of the maintainer to confirm location and inspection finding. Linkage to the maintainer knowledge base of repair workflow and videos will be demonstrated.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
|Navy|2020|$200,000|non-destructive inspection, expeditionary aviation maintenance, repair support system, damage classification, predictive analytics, autonomous inspection, condition-based maintenance, neural network engine|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards/Reports/JH/#2175)