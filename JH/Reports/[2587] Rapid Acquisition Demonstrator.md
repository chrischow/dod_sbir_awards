
Rapid Acquisition Demonstrator
==============================

# Abstract


This proposal is for a feasibility study on the creation of an integrated software development platform to demonstrate how software projects can rapidly, reliably, and securely be created nearly on-demand. Furthermore, this study attempts to solve the rating and vetting of developers problem, based on their code quality, efficiency, and work product, using a novel machine learning system.The study contemplates a work-cloud of microservices, accessible only through unique VPN (virtual private network) keys. For the study, three development teams will be chosen, and given an identical set of projects to develop. Team members and their code will ranked through an AI (artificial intelligence) program module that will assemble and evaluate their code product. The AI-based program will quantitatively evaluate each programmers skills and efficiency, and render a report card of sorts, ranking them on an intuitive number of metrics.The proposed system will cohesively combine our own procedures and processes with open-source platforms. The system will employ metrics from several sources, including academic papers, studies and tests of our design. As its end-product, the evaluation system will generate an unbiased performance rating that will auto-vet and rank each programmer or developer to be considered for a given project.  

# Award Details

|Branch|Award Year|Award Amount|Keywords|
| :---: | :---: | :---: | :---: |
|Special Operations Command|2018|$95,202|programming, software development, machine learning, artificial intelligence, cloud-based, sentiment analysis, program rating system, software review|
  
  


[Back to Home](https://github.com/chrischow/dod_sbir_awards/JH/#2587)